{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d24903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book. \n",
    "It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. \n",
    "It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, \n",
    "and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
    "Why do we use it?\n",
    "It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. \n",
    "The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, \n",
    "content here', making it look like readable English. Many desktop publishing packages and web page editors \n",
    "now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites \n",
    "still in their infancy. Various versions have evolved over the years, sometimes by accident, \n",
    "sometimes on purpose (injected humour and the like).\n",
    "Where does it come from?\n",
    "Contrary to popular belief, Lorem Ipsum is not simply random text. \n",
    "It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. \n",
    "Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, \n",
    "consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered \n",
    "the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" \n",
    "(The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, \n",
    "very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", \n",
    "comes from a line in section 1.10.32.\n",
    "The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. \n",
    "Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, \n",
    "accompanied by English versions from the 1914 translation by H. Rackham.\n",
    "Where can I get some?\n",
    "There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, \n",
    "by injected humour, or randomised words which don't look even slightly believable.\n",
    "If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in \n",
    "the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, \n",
    "making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words,\n",
    "combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. \n",
    "The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4facf509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6617b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d935e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29291e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'lorem': 3,\n",
       " 'ipsum': 4,\n",
       " 'a': 5,\n",
       " 'it': 6,\n",
       " 'and': 7,\n",
       " 'in': 8,\n",
       " 'from': 9,\n",
       " 'is': 10,\n",
       " 'to': 11,\n",
       " 'by': 12,\n",
       " 'text': 13,\n",
       " '1': 14,\n",
       " '10': 15,\n",
       " 'has': 16,\n",
       " 'on': 17,\n",
       " 'latin': 18,\n",
       " 'words': 19,\n",
       " 'with': 20,\n",
       " 'more': 21,\n",
       " 'like': 22,\n",
       " 'versions': 23,\n",
       " 'use': 24,\n",
       " 'or': 25,\n",
       " 'as': 26,\n",
       " 'making': 27,\n",
       " 'many': 28,\n",
       " 'their': 29,\n",
       " 'over': 30,\n",
       " 'injected': 31,\n",
       " 'humour': 32,\n",
       " '32': 33,\n",
       " 'are': 34,\n",
       " 'simply': 35,\n",
       " 'dummy': 36,\n",
       " 'typesetting': 37,\n",
       " 'standard': 38,\n",
       " 'since': 39,\n",
       " '1500s': 40,\n",
       " 'when': 41,\n",
       " 'type': 42,\n",
       " 'book': 43,\n",
       " 'not': 44,\n",
       " 'but': 45,\n",
       " 'also': 46,\n",
       " 'passages': 47,\n",
       " 'desktop': 48,\n",
       " 'publishing': 49,\n",
       " 'that': 50,\n",
       " 'will': 51,\n",
       " 'be': 52,\n",
       " 'readable': 53,\n",
       " 'content': 54,\n",
       " 'page': 55,\n",
       " 'at': 56,\n",
       " 'using': 57,\n",
       " 'look': 58,\n",
       " 'english': 59,\n",
       " 'web': 60,\n",
       " 'model': 61,\n",
       " 'for': 62,\n",
       " 'have': 63,\n",
       " 'years': 64,\n",
       " 'sometimes': 65,\n",
       " 'where': 66,\n",
       " 'popular': 67,\n",
       " 'classical': 68,\n",
       " 'literature': 69,\n",
       " '45': 70,\n",
       " 'bc': 71,\n",
       " 'passage': 72,\n",
       " 'going': 73,\n",
       " 'comes': 74,\n",
       " 'sections': 75,\n",
       " '33': 76,\n",
       " 'de': 77,\n",
       " 'finibus': 78,\n",
       " 'bonorum': 79,\n",
       " 'et': 80,\n",
       " 'malorum': 81,\n",
       " 'cicero': 82,\n",
       " 'this': 83,\n",
       " 'first': 84,\n",
       " 'line': 85,\n",
       " 'reproduced': 86,\n",
       " 'form': 87,\n",
       " 'some': 88,\n",
       " 'there': 89,\n",
       " 'which': 90,\n",
       " 'you': 91,\n",
       " 'internet': 92,\n",
       " 'printing': 93,\n",
       " 'industry': 94,\n",
       " 'been': 95,\n",
       " \"industry's\": 96,\n",
       " 'ever': 97,\n",
       " 'an': 98,\n",
       " 'unknown': 99,\n",
       " 'printer': 100,\n",
       " 'took': 101,\n",
       " 'galley': 102,\n",
       " 'scrambled': 103,\n",
       " 'make': 104,\n",
       " 'specimen': 105,\n",
       " 'survived': 106,\n",
       " 'only': 107,\n",
       " 'five': 108,\n",
       " 'centuries': 109,\n",
       " 'leap': 110,\n",
       " 'into': 111,\n",
       " 'electronic': 112,\n",
       " 'remaining': 113,\n",
       " 'essentially': 114,\n",
       " 'unchanged': 115,\n",
       " 'was': 116,\n",
       " 'popularised': 117,\n",
       " '1960s': 118,\n",
       " 'release': 119,\n",
       " 'letraset': 120,\n",
       " 'sheets': 121,\n",
       " 'containing': 122,\n",
       " 'recently': 123,\n",
       " 'software': 124,\n",
       " 'aldus': 125,\n",
       " 'pagemaker': 126,\n",
       " 'including': 127,\n",
       " 'why': 128,\n",
       " 'do': 129,\n",
       " 'we': 130,\n",
       " 'long': 131,\n",
       " 'established': 132,\n",
       " 'fact': 133,\n",
       " 'reader': 134,\n",
       " 'distracted': 135,\n",
       " 'looking': 136,\n",
       " 'its': 137,\n",
       " 'layout': 138,\n",
       " 'point': 139,\n",
       " 'less': 140,\n",
       " 'normal': 141,\n",
       " 'distribution': 142,\n",
       " 'letters': 143,\n",
       " 'opposed': 144,\n",
       " \"'content\": 145,\n",
       " 'here': 146,\n",
       " \"here'\": 147,\n",
       " 'packages': 148,\n",
       " 'editors': 149,\n",
       " 'now': 150,\n",
       " 'default': 151,\n",
       " 'search': 152,\n",
       " \"'lorem\": 153,\n",
       " \"ipsum'\": 154,\n",
       " 'uncover': 155,\n",
       " 'sites': 156,\n",
       " 'still': 157,\n",
       " 'infancy': 158,\n",
       " 'various': 159,\n",
       " 'evolved': 160,\n",
       " 'accident': 161,\n",
       " 'purpose': 162,\n",
       " 'does': 163,\n",
       " 'come': 164,\n",
       " 'contrary': 165,\n",
       " 'belief': 166,\n",
       " 'random': 167,\n",
       " 'roots': 168,\n",
       " 'piece': 169,\n",
       " '2000': 170,\n",
       " 'old': 171,\n",
       " 'richard': 172,\n",
       " 'mcclintock': 173,\n",
       " 'professor': 174,\n",
       " 'hampden': 175,\n",
       " 'sydney': 176,\n",
       " 'college': 177,\n",
       " 'virginia': 178,\n",
       " 'looked': 179,\n",
       " 'up': 180,\n",
       " 'one': 181,\n",
       " 'obscure': 182,\n",
       " 'consectetur': 183,\n",
       " 'through': 184,\n",
       " 'cites': 185,\n",
       " 'word': 186,\n",
       " 'discovered': 187,\n",
       " 'undoubtable': 188,\n",
       " 'source': 189,\n",
       " 'extremes': 190,\n",
       " 'good': 191,\n",
       " 'evil': 192,\n",
       " 'written': 193,\n",
       " 'treatise': 194,\n",
       " 'theory': 195,\n",
       " 'ethics': 196,\n",
       " 'very': 197,\n",
       " 'during': 198,\n",
       " 'renaissance': 199,\n",
       " 'dolor': 200,\n",
       " 'sit': 201,\n",
       " 'amet': 202,\n",
       " 'section': 203,\n",
       " 'chunk': 204,\n",
       " 'used': 205,\n",
       " 'below': 206,\n",
       " 'those': 207,\n",
       " 'interested': 208,\n",
       " 'exact': 209,\n",
       " 'original': 210,\n",
       " 'accompanied': 211,\n",
       " '1914': 212,\n",
       " 'translation': 213,\n",
       " 'h': 214,\n",
       " 'rackham': 215,\n",
       " 'can': 216,\n",
       " 'i': 217,\n",
       " 'get': 218,\n",
       " 'variations': 219,\n",
       " 'available': 220,\n",
       " 'majority': 221,\n",
       " 'suffered': 222,\n",
       " 'alteration': 223,\n",
       " 'randomised': 224,\n",
       " \"don't\": 225,\n",
       " 'even': 226,\n",
       " 'slightly': 227,\n",
       " 'believable': 228,\n",
       " 'if': 229,\n",
       " 'need': 230,\n",
       " 'sure': 231,\n",
       " \"isn't\": 232,\n",
       " 'anything': 233,\n",
       " 'embarrassing': 234,\n",
       " 'hidden': 235,\n",
       " 'middle': 236,\n",
       " 'all': 237,\n",
       " 'generators': 238,\n",
       " 'tend': 239,\n",
       " 'repeat': 240,\n",
       " 'predefined': 241,\n",
       " 'chunks': 242,\n",
       " 'necessary': 243,\n",
       " 'true': 244,\n",
       " 'generator': 245,\n",
       " 'uses': 246,\n",
       " 'dictionary': 247,\n",
       " '200': 248,\n",
       " 'combined': 249,\n",
       " 'handful': 250,\n",
       " 'sentence': 251,\n",
       " 'structures': 252,\n",
       " 'generate': 253,\n",
       " 'looks': 254,\n",
       " 'reasonable': 255,\n",
       " 'generated': 256,\n",
       " 'therefore': 257,\n",
       " 'always': 258,\n",
       " 'free': 259,\n",
       " 'repetition': 260,\n",
       " 'non': 261,\n",
       " 'characteristic': 262,\n",
       " 'etc': 263}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2ce71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a96c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59afb214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem Ipsum is simply dummy text of the printing and typesetting industry. \n",
      "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a galley of type and scrambled it to make a type specimen book. \n",
      "It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. \n",
      "It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, \n",
      "and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\n",
      "Why do we use it?\n",
      "It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. \n",
      "The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using 'Content here, \n",
      "content here', making it look like readable English. Many desktop publishing packages and web page editors \n",
      "now use Lorem Ipsum as their default model text, and a search for 'lorem ipsum' will uncover many web sites \n",
      "still in their infancy. Various versions have evolved over the years, sometimes by accident, \n",
      "sometimes on purpose (injected humour and the like).\n",
      "Where does it come from?\n",
      "Contrary to popular belief, Lorem Ipsum is not simply random text. \n",
      "It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. \n",
      "Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, \n",
      "consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered \n",
      "the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" \n",
      "(The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, \n",
      "very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", \n",
      "comes from a line in section 1.10.32.\n",
      "The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. \n",
      "Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, \n",
      "accompanied by English versions from the 1914 translation by H. Rackham.\n",
      "Where can I get some?\n",
      "There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, \n",
      "by injected humour, or randomised words which don't look even slightly believable.\n",
      "If you are going to use a passage of Lorem Ipsum, you need to be sure there isn't anything embarrassing hidden in \n",
      "the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, \n",
      "making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words,\n",
      "combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. \n",
      "The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e1897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 10, 35, 36, 13, 2, 1, 93, 7, 37, 94]\n",
      "[3, 4, 16, 95, 1, 96, 38, 36, 13, 97, 39, 1, 40]\n",
      "[41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11, 104, 5, 42, 105, 43]\n",
      "[6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111, 112, 37, 113, 114, 115]\n",
      "[6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120, 121, 122, 3, 4, 47]\n",
      "[7, 21, 123, 20, 48, 49, 124, 22, 125, 126, 127, 23, 2, 3, 4]\n",
      "[128, 129, 130, 24, 6]\n",
      "[6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1, 53, 54, 2, 5, 55, 41, 136, 56, 137, 138]\n",
      "[1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140, 141, 142, 2, 143, 26, 144, 11, 57, 145, 146]\n",
      "[54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49, 148, 7, 60, 55, 149]\n",
      "[150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62, 153, 154, 51, 155, 28, 60, 156]\n",
      "[157, 8, 29, 158, 159, 23, 63, 160, 30, 1, 64, 65, 12, 161]\n",
      "[65, 17, 162, 31, 32, 7, 1, 22]\n",
      "[66, 163, 6, 164, 9]\n",
      "[165, 11, 67, 166, 3, 4, 10, 44, 35, 167, 13]\n",
      "[6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27, 6, 30, 170, 64, 171]\n",
      "[172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179, 180, 181, 2, 1, 21, 182, 18, 19]\n",
      "[183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1, 186, 8, 68, 69, 187]\n",
      "[1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76, 2, 77, 78, 79, 80, 81]\n",
      "[1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43, 10, 5, 194, 17, 1, 195, 2, 196]\n",
      "[197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4, 3, 4, 200, 201, 202]\n",
      "[74, 9, 5, 85, 8, 203, 14, 15, 33]\n",
      "[1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10, 86, 206, 62, 207, 208]\n",
      "[75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12, 82, 34, 46, 86, 8, 29, 209, 210, 87]\n",
      "[211, 12, 59, 23, 9, 1, 212, 213, 12, 214, 215]\n",
      "[66, 216, 217, 218, 88]\n",
      "[89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63, 222, 223, 8, 88, 87]\n",
      "[12, 31, 32, 25, 224, 19, 90, 225, 58, 226, 227, 228]\n",
      "[229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11, 52, 231, 89, 232, 233, 234, 235, 8]\n",
      "[1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239, 11, 240, 241, 242, 26, 243]\n",
      "[27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247, 2, 30, 248, 18, 19]\n",
      "[249, 20, 5, 250, 2, 61, 251, 252, 11, 253, 3, 4, 90, 254, 255]\n",
      "[1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32, 25, 261, 262, 19, 263]\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(tokenizer.texts_to_sequences([sentence])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97619d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for sentence in faqs.split('\\n'):\n",
    "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "  for i in range(1,len(tokenized_sentence)):\n",
    "    input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ceb226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4],\n",
       " [3, 4, 10],\n",
       " [3, 4, 10, 35],\n",
       " [3, 4, 10, 35, 36],\n",
       " [3, 4, 10, 35, 36, 13],\n",
       " [3, 4, 10, 35, 36, 13, 2],\n",
       " [3, 4, 10, 35, 36, 13, 2, 1],\n",
       " [3, 4, 10, 35, 36, 13, 2, 1, 93],\n",
       " [3, 4, 10, 35, 36, 13, 2, 1, 93, 7],\n",
       " [3, 4, 10, 35, 36, 13, 2, 1, 93, 7, 37],\n",
       " [3, 4, 10, 35, 36, 13, 2, 1, 93, 7, 37, 94],\n",
       " [3, 4],\n",
       " [3, 4, 16],\n",
       " [3, 4, 16, 95],\n",
       " [3, 4, 16, 95, 1],\n",
       " [3, 4, 16, 95, 1, 96],\n",
       " [3, 4, 16, 95, 1, 96, 38],\n",
       " [3, 4, 16, 95, 1, 96, 38, 36],\n",
       " [3, 4, 16, 95, 1, 96, 38, 36, 13],\n",
       " [3, 4, 16, 95, 1, 96, 38, 36, 13, 97],\n",
       " [3, 4, 16, 95, 1, 96, 38, 36, 13, 97, 39],\n",
       " [3, 4, 16, 95, 1, 96, 38, 36, 13, 97, 39, 1],\n",
       " [3, 4, 16, 95, 1, 96, 38, 36, 13, 97, 39, 1, 40],\n",
       " [41, 98],\n",
       " [41, 98, 99],\n",
       " [41, 98, 99, 100],\n",
       " [41, 98, 99, 100, 101],\n",
       " [41, 98, 99, 100, 101, 5],\n",
       " [41, 98, 99, 100, 101, 5, 102],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11, 104],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11, 104, 5],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11, 104, 5, 42],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11, 104, 5, 42, 105],\n",
       " [41, 98, 99, 100, 101, 5, 102, 2, 42, 7, 103, 6, 11, 104, 5, 42, 105, 43],\n",
       " [6, 16],\n",
       " [6, 16, 106],\n",
       " [6, 16, 106, 44],\n",
       " [6, 16, 106, 44, 107],\n",
       " [6, 16, 106, 44, 107, 108],\n",
       " [6, 16, 106, 44, 107, 108, 109],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111, 112],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111, 112, 37],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111, 112, 37, 113],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111, 112, 37, 113, 114],\n",
       " [6, 16, 106, 44, 107, 108, 109, 45, 46, 1, 110, 111, 112, 37, 113, 114, 115],\n",
       " [6, 116],\n",
       " [6, 116, 117],\n",
       " [6, 116, 117, 8],\n",
       " [6, 116, 117, 8, 1],\n",
       " [6, 116, 117, 8, 1, 118],\n",
       " [6, 116, 117, 8, 1, 118, 20],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120, 121],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120, 121, 122],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120, 121, 122, 3],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120, 121, 122, 3, 4],\n",
       " [6, 116, 117, 8, 1, 118, 20, 1, 119, 2, 120, 121, 122, 3, 4, 47],\n",
       " [7, 21],\n",
       " [7, 21, 123],\n",
       " [7, 21, 123, 20],\n",
       " [7, 21, 123, 20, 48],\n",
       " [7, 21, 123, 20, 48, 49],\n",
       " [7, 21, 123, 20, 48, 49, 124],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125, 126],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125, 126, 127],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125, 126, 127, 23],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125, 126, 127, 23, 2],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125, 126, 127, 23, 2, 3],\n",
       " [7, 21, 123, 20, 48, 49, 124, 22, 125, 126, 127, 23, 2, 3, 4],\n",
       " [128, 129],\n",
       " [128, 129, 130],\n",
       " [128, 129, 130, 24],\n",
       " [128, 129, 130, 24, 6],\n",
       " [6, 10],\n",
       " [6, 10, 5],\n",
       " [6, 10, 5, 131],\n",
       " [6, 10, 5, 131, 132],\n",
       " [6, 10, 5, 131, 132, 133],\n",
       " [6, 10, 5, 131, 132, 133, 50],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1, 53],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1, 53, 54],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1, 53, 54, 2],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1, 53, 54, 2, 5],\n",
       " [6, 10, 5, 131, 132, 133, 50, 5, 134, 51, 52, 135, 12, 1, 53, 54, 2, 5, 55],\n",
       " [6,\n",
       "  10,\n",
       "  5,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  50,\n",
       "  5,\n",
       "  134,\n",
       "  51,\n",
       "  52,\n",
       "  135,\n",
       "  12,\n",
       "  1,\n",
       "  53,\n",
       "  54,\n",
       "  2,\n",
       "  5,\n",
       "  55,\n",
       "  41],\n",
       " [6,\n",
       "  10,\n",
       "  5,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  50,\n",
       "  5,\n",
       "  134,\n",
       "  51,\n",
       "  52,\n",
       "  135,\n",
       "  12,\n",
       "  1,\n",
       "  53,\n",
       "  54,\n",
       "  2,\n",
       "  5,\n",
       "  55,\n",
       "  41,\n",
       "  136],\n",
       " [6,\n",
       "  10,\n",
       "  5,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  50,\n",
       "  5,\n",
       "  134,\n",
       "  51,\n",
       "  52,\n",
       "  135,\n",
       "  12,\n",
       "  1,\n",
       "  53,\n",
       "  54,\n",
       "  2,\n",
       "  5,\n",
       "  55,\n",
       "  41,\n",
       "  136,\n",
       "  56],\n",
       " [6,\n",
       "  10,\n",
       "  5,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  50,\n",
       "  5,\n",
       "  134,\n",
       "  51,\n",
       "  52,\n",
       "  135,\n",
       "  12,\n",
       "  1,\n",
       "  53,\n",
       "  54,\n",
       "  2,\n",
       "  5,\n",
       "  55,\n",
       "  41,\n",
       "  136,\n",
       "  56,\n",
       "  137],\n",
       " [6,\n",
       "  10,\n",
       "  5,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  50,\n",
       "  5,\n",
       "  134,\n",
       "  51,\n",
       "  52,\n",
       "  135,\n",
       "  12,\n",
       "  1,\n",
       "  53,\n",
       "  54,\n",
       "  2,\n",
       "  5,\n",
       "  55,\n",
       "  41,\n",
       "  136,\n",
       "  56,\n",
       "  137,\n",
       "  138],\n",
       " [1, 139],\n",
       " [1, 139, 2],\n",
       " [1, 139, 2, 57],\n",
       " [1, 139, 2, 57, 3],\n",
       " [1, 139, 2, 57, 3, 4],\n",
       " [1, 139, 2, 57, 3, 4, 10],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140, 141],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140, 141, 142],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140, 141, 142, 2],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140, 141, 142, 2, 143],\n",
       " [1, 139, 2, 57, 3, 4, 10, 50, 6, 16, 5, 21, 25, 140, 141, 142, 2, 143, 26],\n",
       " [1,\n",
       "  139,\n",
       "  2,\n",
       "  57,\n",
       "  3,\n",
       "  4,\n",
       "  10,\n",
       "  50,\n",
       "  6,\n",
       "  16,\n",
       "  5,\n",
       "  21,\n",
       "  25,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  2,\n",
       "  143,\n",
       "  26,\n",
       "  144],\n",
       " [1,\n",
       "  139,\n",
       "  2,\n",
       "  57,\n",
       "  3,\n",
       "  4,\n",
       "  10,\n",
       "  50,\n",
       "  6,\n",
       "  16,\n",
       "  5,\n",
       "  21,\n",
       "  25,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  2,\n",
       "  143,\n",
       "  26,\n",
       "  144,\n",
       "  11],\n",
       " [1,\n",
       "  139,\n",
       "  2,\n",
       "  57,\n",
       "  3,\n",
       "  4,\n",
       "  10,\n",
       "  50,\n",
       "  6,\n",
       "  16,\n",
       "  5,\n",
       "  21,\n",
       "  25,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  2,\n",
       "  143,\n",
       "  26,\n",
       "  144,\n",
       "  11,\n",
       "  57],\n",
       " [1,\n",
       "  139,\n",
       "  2,\n",
       "  57,\n",
       "  3,\n",
       "  4,\n",
       "  10,\n",
       "  50,\n",
       "  6,\n",
       "  16,\n",
       "  5,\n",
       "  21,\n",
       "  25,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  2,\n",
       "  143,\n",
       "  26,\n",
       "  144,\n",
       "  11,\n",
       "  57,\n",
       "  145],\n",
       " [1,\n",
       "  139,\n",
       "  2,\n",
       "  57,\n",
       "  3,\n",
       "  4,\n",
       "  10,\n",
       "  50,\n",
       "  6,\n",
       "  16,\n",
       "  5,\n",
       "  21,\n",
       "  25,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  2,\n",
       "  143,\n",
       "  26,\n",
       "  144,\n",
       "  11,\n",
       "  57,\n",
       "  145,\n",
       "  146],\n",
       " [54, 147],\n",
       " [54, 147, 27],\n",
       " [54, 147, 27, 6],\n",
       " [54, 147, 27, 6, 58],\n",
       " [54, 147, 27, 6, 58, 22],\n",
       " [54, 147, 27, 6, 58, 22, 53],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49, 148],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49, 148, 7],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49, 148, 7, 60],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49, 148, 7, 60, 55],\n",
       " [54, 147, 27, 6, 58, 22, 53, 59, 28, 48, 49, 148, 7, 60, 55, 149],\n",
       " [150, 24],\n",
       " [150, 24, 3],\n",
       " [150, 24, 3, 4],\n",
       " [150, 24, 3, 4, 26],\n",
       " [150, 24, 3, 4, 26, 29],\n",
       " [150, 24, 3, 4, 26, 29, 151],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62, 153],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62, 153, 154],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62, 153, 154, 51],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62, 153, 154, 51, 155],\n",
       " [150, 24, 3, 4, 26, 29, 151, 61, 13, 7, 5, 152, 62, 153, 154, 51, 155, 28],\n",
       " [150,\n",
       "  24,\n",
       "  3,\n",
       "  4,\n",
       "  26,\n",
       "  29,\n",
       "  151,\n",
       "  61,\n",
       "  13,\n",
       "  7,\n",
       "  5,\n",
       "  152,\n",
       "  62,\n",
       "  153,\n",
       "  154,\n",
       "  51,\n",
       "  155,\n",
       "  28,\n",
       "  60],\n",
       " [150,\n",
       "  24,\n",
       "  3,\n",
       "  4,\n",
       "  26,\n",
       "  29,\n",
       "  151,\n",
       "  61,\n",
       "  13,\n",
       "  7,\n",
       "  5,\n",
       "  152,\n",
       "  62,\n",
       "  153,\n",
       "  154,\n",
       "  51,\n",
       "  155,\n",
       "  28,\n",
       "  60,\n",
       "  156],\n",
       " [157, 8],\n",
       " [157, 8, 29],\n",
       " [157, 8, 29, 158],\n",
       " [157, 8, 29, 158, 159],\n",
       " [157, 8, 29, 158, 159, 23],\n",
       " [157, 8, 29, 158, 159, 23, 63],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160, 30],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160, 30, 1],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160, 30, 1, 64],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160, 30, 1, 64, 65],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160, 30, 1, 64, 65, 12],\n",
       " [157, 8, 29, 158, 159, 23, 63, 160, 30, 1, 64, 65, 12, 161],\n",
       " [65, 17],\n",
       " [65, 17, 162],\n",
       " [65, 17, 162, 31],\n",
       " [65, 17, 162, 31, 32],\n",
       " [65, 17, 162, 31, 32, 7],\n",
       " [65, 17, 162, 31, 32, 7, 1],\n",
       " [65, 17, 162, 31, 32, 7, 1, 22],\n",
       " [66, 163],\n",
       " [66, 163, 6],\n",
       " [66, 163, 6, 164],\n",
       " [66, 163, 6, 164, 9],\n",
       " [165, 11],\n",
       " [165, 11, 67],\n",
       " [165, 11, 67, 166],\n",
       " [165, 11, 67, 166, 3],\n",
       " [165, 11, 67, 166, 3, 4],\n",
       " [165, 11, 67, 166, 3, 4, 10],\n",
       " [165, 11, 67, 166, 3, 4, 10, 44],\n",
       " [165, 11, 67, 166, 3, 4, 10, 44, 35],\n",
       " [165, 11, 67, 166, 3, 4, 10, 44, 35, 167],\n",
       " [165, 11, 67, 166, 3, 4, 10, 44, 35, 167, 13],\n",
       " [6, 16],\n",
       " [6, 16, 168],\n",
       " [6, 16, 168, 8],\n",
       " [6, 16, 168, 8, 5],\n",
       " [6, 16, 168, 8, 5, 169],\n",
       " [6, 16, 168, 8, 5, 169, 2],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27, 6],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27, 6, 30],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27, 6, 30, 170],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27, 6, 30, 170, 64],\n",
       " [6, 16, 168, 8, 5, 169, 2, 68, 18, 69, 9, 70, 71, 27, 6, 30, 170, 64, 171],\n",
       " [172, 173],\n",
       " [172, 173, 5],\n",
       " [172, 173, 5, 18],\n",
       " [172, 173, 5, 18, 174],\n",
       " [172, 173, 5, 18, 174, 56],\n",
       " [172, 173, 5, 18, 174, 56, 175],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179, 180],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179, 180, 181],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179, 180, 181, 2],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179, 180, 181, 2, 1],\n",
       " [172, 173, 5, 18, 174, 56, 175, 176, 177, 8, 178, 179, 180, 181, 2, 1, 21],\n",
       " [172,\n",
       "  173,\n",
       "  5,\n",
       "  18,\n",
       "  174,\n",
       "  56,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  8,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  2,\n",
       "  1,\n",
       "  21,\n",
       "  182],\n",
       " [172,\n",
       "  173,\n",
       "  5,\n",
       "  18,\n",
       "  174,\n",
       "  56,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  8,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  2,\n",
       "  1,\n",
       "  21,\n",
       "  182,\n",
       "  18],\n",
       " [172,\n",
       "  173,\n",
       "  5,\n",
       "  18,\n",
       "  174,\n",
       "  56,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  8,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  2,\n",
       "  1,\n",
       "  21,\n",
       "  182,\n",
       "  18,\n",
       "  19],\n",
       " [183, 9],\n",
       " [183, 9, 5],\n",
       " [183, 9, 5, 3],\n",
       " [183, 9, 5, 3, 4],\n",
       " [183, 9, 5, 3, 4, 72],\n",
       " [183, 9, 5, 3, 4, 72, 7],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1, 186],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1, 186, 8],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1, 186, 8, 68],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1, 186, 8, 68, 69],\n",
       " [183, 9, 5, 3, 4, 72, 7, 73, 184, 1, 185, 2, 1, 186, 8, 68, 69, 187],\n",
       " [1, 188],\n",
       " [1, 188, 189],\n",
       " [1, 188, 189, 3],\n",
       " [1, 188, 189, 3, 4],\n",
       " [1, 188, 189, 3, 4, 74],\n",
       " [1, 188, 189, 3, 4, 74, 9],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76, 2],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76, 2, 77],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76, 2, 77, 78],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76, 2, 77, 78, 79],\n",
       " [1, 188, 189, 3, 4, 74, 9, 75, 14, 15, 33, 7, 14, 15, 76, 2, 77, 78, 79, 80],\n",
       " [1,\n",
       "  188,\n",
       "  189,\n",
       "  3,\n",
       "  4,\n",
       "  74,\n",
       "  9,\n",
       "  75,\n",
       "  14,\n",
       "  15,\n",
       "  33,\n",
       "  7,\n",
       "  14,\n",
       "  15,\n",
       "  76,\n",
       "  2,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81],\n",
       " [1, 190],\n",
       " [1, 190, 2],\n",
       " [1, 190, 2, 191],\n",
       " [1, 190, 2, 191, 7],\n",
       " [1, 190, 2, 191, 7, 192],\n",
       " [1, 190, 2, 191, 7, 192, 12],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43, 10],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43, 10, 5],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43, 10, 5, 194],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43, 10, 5, 194, 17],\n",
       " [1, 190, 2, 191, 7, 192, 12, 82, 193, 8, 70, 71, 83, 43, 10, 5, 194, 17, 1],\n",
       " [1,\n",
       "  190,\n",
       "  2,\n",
       "  191,\n",
       "  7,\n",
       "  192,\n",
       "  12,\n",
       "  82,\n",
       "  193,\n",
       "  8,\n",
       "  70,\n",
       "  71,\n",
       "  83,\n",
       "  43,\n",
       "  10,\n",
       "  5,\n",
       "  194,\n",
       "  17,\n",
       "  1,\n",
       "  195],\n",
       " [1,\n",
       "  190,\n",
       "  2,\n",
       "  191,\n",
       "  7,\n",
       "  192,\n",
       "  12,\n",
       "  82,\n",
       "  193,\n",
       "  8,\n",
       "  70,\n",
       "  71,\n",
       "  83,\n",
       "  43,\n",
       "  10,\n",
       "  5,\n",
       "  194,\n",
       "  17,\n",
       "  1,\n",
       "  195,\n",
       "  2],\n",
       " [1,\n",
       "  190,\n",
       "  2,\n",
       "  191,\n",
       "  7,\n",
       "  192,\n",
       "  12,\n",
       "  82,\n",
       "  193,\n",
       "  8,\n",
       "  70,\n",
       "  71,\n",
       "  83,\n",
       "  43,\n",
       "  10,\n",
       "  5,\n",
       "  194,\n",
       "  17,\n",
       "  1,\n",
       "  195,\n",
       "  2,\n",
       "  196],\n",
       " [197, 67],\n",
       " [197, 67, 198],\n",
       " [197, 67, 198, 1],\n",
       " [197, 67, 198, 1, 199],\n",
       " [197, 67, 198, 1, 199, 1],\n",
       " [197, 67, 198, 1, 199, 1, 84],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4, 3],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4, 3, 4],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4, 3, 4, 200],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4, 3, 4, 200, 201],\n",
       " [197, 67, 198, 1, 199, 1, 84, 85, 2, 3, 4, 3, 4, 200, 201, 202],\n",
       " [74, 9],\n",
       " [74, 9, 5],\n",
       " [74, 9, 5, 85],\n",
       " [74, 9, 5, 85, 8],\n",
       " [74, 9, 5, 85, 8, 203],\n",
       " [74, 9, 5, 85, 8, 203, 14],\n",
       " [74, 9, 5, 85, 8, 203, 14, 15],\n",
       " [74, 9, 5, 85, 8, 203, 14, 15, 33],\n",
       " [1, 38],\n",
       " [1, 38, 204],\n",
       " [1, 38, 204, 2],\n",
       " [1, 38, 204, 2, 3],\n",
       " [1, 38, 204, 2, 3, 4],\n",
       " [1, 38, 204, 2, 3, 4, 205],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10, 86],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10, 86, 206],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10, 86, 206, 62],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10, 86, 206, 62, 207],\n",
       " [1, 38, 204, 2, 3, 4, 205, 39, 1, 40, 10, 86, 206, 62, 207, 208],\n",
       " [75, 14],\n",
       " [75, 14, 15],\n",
       " [75, 14, 15, 33],\n",
       " [75, 14, 15, 33, 7],\n",
       " [75, 14, 15, 33, 7, 14],\n",
       " [75, 14, 15, 33, 7, 14, 15],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12, 82],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12, 82, 34],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12, 82, 34, 46],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12, 82, 34, 46, 86],\n",
       " [75, 14, 15, 33, 7, 14, 15, 76, 9, 77, 78, 79, 80, 81, 12, 82, 34, 46, 86, 8],\n",
       " [75,\n",
       "  14,\n",
       "  15,\n",
       "  33,\n",
       "  7,\n",
       "  14,\n",
       "  15,\n",
       "  76,\n",
       "  9,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  12,\n",
       "  82,\n",
       "  34,\n",
       "  46,\n",
       "  86,\n",
       "  8,\n",
       "  29],\n",
       " [75,\n",
       "  14,\n",
       "  15,\n",
       "  33,\n",
       "  7,\n",
       "  14,\n",
       "  15,\n",
       "  76,\n",
       "  9,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  12,\n",
       "  82,\n",
       "  34,\n",
       "  46,\n",
       "  86,\n",
       "  8,\n",
       "  29,\n",
       "  209],\n",
       " [75,\n",
       "  14,\n",
       "  15,\n",
       "  33,\n",
       "  7,\n",
       "  14,\n",
       "  15,\n",
       "  76,\n",
       "  9,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  12,\n",
       "  82,\n",
       "  34,\n",
       "  46,\n",
       "  86,\n",
       "  8,\n",
       "  29,\n",
       "  209,\n",
       "  210],\n",
       " [75,\n",
       "  14,\n",
       "  15,\n",
       "  33,\n",
       "  7,\n",
       "  14,\n",
       "  15,\n",
       "  76,\n",
       "  9,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  12,\n",
       "  82,\n",
       "  34,\n",
       "  46,\n",
       "  86,\n",
       "  8,\n",
       "  29,\n",
       "  209,\n",
       "  210,\n",
       "  87],\n",
       " [211, 12],\n",
       " [211, 12, 59],\n",
       " [211, 12, 59, 23],\n",
       " [211, 12, 59, 23, 9],\n",
       " [211, 12, 59, 23, 9, 1],\n",
       " [211, 12, 59, 23, 9, 1, 212],\n",
       " [211, 12, 59, 23, 9, 1, 212, 213],\n",
       " [211, 12, 59, 23, 9, 1, 212, 213, 12],\n",
       " [211, 12, 59, 23, 9, 1, 212, 213, 12, 214],\n",
       " [211, 12, 59, 23, 9, 1, 212, 213, 12, 214, 215],\n",
       " [66, 216],\n",
       " [66, 216, 217],\n",
       " [66, 216, 217, 218],\n",
       " [66, 216, 217, 218, 88],\n",
       " [89, 34],\n",
       " [89, 34, 28],\n",
       " [89, 34, 28, 219],\n",
       " [89, 34, 28, 219, 2],\n",
       " [89, 34, 28, 219, 2, 47],\n",
       " [89, 34, 28, 219, 2, 47, 2],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63, 222],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63, 222, 223],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63, 222, 223, 8],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63, 222, 223, 8, 88],\n",
       " [89, 34, 28, 219, 2, 47, 2, 3, 4, 220, 45, 1, 221, 63, 222, 223, 8, 88, 87],\n",
       " [12, 31],\n",
       " [12, 31, 32],\n",
       " [12, 31, 32, 25],\n",
       " [12, 31, 32, 25, 224],\n",
       " [12, 31, 32, 25, 224, 19],\n",
       " [12, 31, 32, 25, 224, 19, 90],\n",
       " [12, 31, 32, 25, 224, 19, 90, 225],\n",
       " [12, 31, 32, 25, 224, 19, 90, 225, 58],\n",
       " [12, 31, 32, 25, 224, 19, 90, 225, 58, 226],\n",
       " [12, 31, 32, 25, 224, 19, 90, 225, 58, 226, 227],\n",
       " [12, 31, 32, 25, 224, 19, 90, 225, 58, 226, 227, 228],\n",
       " [229, 91],\n",
       " [229, 91, 34],\n",
       " [229, 91, 34, 73],\n",
       " [229, 91, 34, 73, 11],\n",
       " [229, 91, 34, 73, 11, 24],\n",
       " [229, 91, 34, 73, 11, 24, 5],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11, 52],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11, 52, 231],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11, 52, 231, 89],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11, 52, 231, 89, 232],\n",
       " [229, 91, 34, 73, 11, 24, 5, 72, 2, 3, 4, 91, 230, 11, 52, 231, 89, 232, 233],\n",
       " [229,\n",
       "  91,\n",
       "  34,\n",
       "  73,\n",
       "  11,\n",
       "  24,\n",
       "  5,\n",
       "  72,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  91,\n",
       "  230,\n",
       "  11,\n",
       "  52,\n",
       "  231,\n",
       "  89,\n",
       "  232,\n",
       "  233,\n",
       "  234],\n",
       " [229,\n",
       "  91,\n",
       "  34,\n",
       "  73,\n",
       "  11,\n",
       "  24,\n",
       "  5,\n",
       "  72,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  91,\n",
       "  230,\n",
       "  11,\n",
       "  52,\n",
       "  231,\n",
       "  89,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235],\n",
       " [229,\n",
       "  91,\n",
       "  34,\n",
       "  73,\n",
       "  11,\n",
       "  24,\n",
       "  5,\n",
       "  72,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  91,\n",
       "  230,\n",
       "  11,\n",
       "  52,\n",
       "  231,\n",
       "  89,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  8],\n",
       " [1, 236],\n",
       " [1, 236, 2],\n",
       " [1, 236, 2, 13],\n",
       " [1, 236, 2, 13, 237],\n",
       " [1, 236, 2, 13, 237, 1],\n",
       " [1, 236, 2, 13, 237, 1, 3],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239, 11],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239, 11, 240],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239, 11, 240, 241],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239, 11, 240, 241, 242],\n",
       " [1, 236, 2, 13, 237, 1, 3, 4, 238, 17, 1, 92, 239, 11, 240, 241, 242, 26],\n",
       " [1,\n",
       "  236,\n",
       "  2,\n",
       "  13,\n",
       "  237,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  238,\n",
       "  17,\n",
       "  1,\n",
       "  92,\n",
       "  239,\n",
       "  11,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  26,\n",
       "  243],\n",
       " [27, 83],\n",
       " [27, 83, 1],\n",
       " [27, 83, 1, 84],\n",
       " [27, 83, 1, 84, 244],\n",
       " [27, 83, 1, 84, 244, 245],\n",
       " [27, 83, 1, 84, 244, 245, 17],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247, 2],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247, 2, 30],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247, 2, 30, 248],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247, 2, 30, 248, 18],\n",
       " [27, 83, 1, 84, 244, 245, 17, 1, 92, 6, 246, 5, 247, 2, 30, 248, 18, 19],\n",
       " [249, 20],\n",
       " [249, 20, 5],\n",
       " [249, 20, 5, 250],\n",
       " [249, 20, 5, 250, 2],\n",
       " [249, 20, 5, 250, 2, 61],\n",
       " [249, 20, 5, 250, 2, 61, 251],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11, 253],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11, 253, 3],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11, 253, 3, 4],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11, 253, 3, 4, 90],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11, 253, 3, 4, 90, 254],\n",
       " [249, 20, 5, 250, 2, 61, 251, 252, 11, 253, 3, 4, 90, 254, 255],\n",
       " [1, 256],\n",
       " [1, 256, 3],\n",
       " [1, 256, 3, 4],\n",
       " [1, 256, 3, 4, 10],\n",
       " [1, 256, 3, 4, 10, 257],\n",
       " [1, 256, 3, 4, 10, 257, 258],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32, 25],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32, 25, 261],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32, 25, 261, 262],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32, 25, 261, 262, 19],\n",
       " [1, 256, 3, 4, 10, 257, 258, 259, 9, 260, 31, 32, 25, 261, 262, 19, 263]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d10f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in input_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0124d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(x) for x in input_sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f315f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13bae27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   3,   4],\n",
       "       [  0,   0,   0, ...,   3,   4,  10],\n",
       "       [  0,   0,   0, ...,   4,  10,  35],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  25, 261, 262],\n",
       "       [  0,   0,   0, ..., 261, 262,  19],\n",
       "       [  0,   0,   0, ..., 262,  19, 263]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59aa24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62a067cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa393a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a57f413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "032203d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52253003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y,num_classes=L+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0a2ede9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "799da0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 264)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eba4c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b22fcf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(y.shape[1], 100, input_length=X.shape[1]))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5f699dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c282457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 23, 100)           26400     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 300)               481200    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 264)               79464     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 587064 (2.24 MB)\n",
      "Trainable params: 587064 (2.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "879682ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "16/16 [==============================] - 4s 71ms/step - loss: 5.5142 - accuracy: 0.0328\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 5.2819 - accuracy: 0.0389\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 5.1743 - accuracy: 0.0451\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 5.1316 - accuracy: 0.0492\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 5.0934 - accuracy: 0.0451\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 5.0607 - accuracy: 0.0512\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 5.0017 - accuracy: 0.0738\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 4.9403 - accuracy: 0.0676\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.8445 - accuracy: 0.0820\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.7338 - accuracy: 0.0656\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.5827 - accuracy: 0.0984\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.4171 - accuracy: 0.1045\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.2364 - accuracy: 0.1148\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.0348 - accuracy: 0.1311\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.8139 - accuracy: 0.1598\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 3.5619 - accuracy: 0.1926\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.3186 - accuracy: 0.2254\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.0408 - accuracy: 0.2398\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.8232 - accuracy: 0.2869\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.6060 - accuracy: 0.3340\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.3883 - accuracy: 0.3750\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.1522 - accuracy: 0.4488\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 1.9564 - accuracy: 0.5184\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 1.7759 - accuracy: 0.5881\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 1.6163 - accuracy: 0.6393\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 1.4488 - accuracy: 0.6865\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 1.3133 - accuracy: 0.7398\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 1.2004 - accuracy: 0.7582\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 1.0883 - accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.9623 - accuracy: 0.8627\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.8641 - accuracy: 0.8791\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.7862 - accuracy: 0.8873\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.7501 - accuracy: 0.9037\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.6710 - accuracy: 0.9180\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.5914 - accuracy: 0.9344\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.5365 - accuracy: 0.9488\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.4921 - accuracy: 0.9447\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.4461 - accuracy: 0.9590\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.4178 - accuracy: 0.9508\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.3857 - accuracy: 0.9529\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.3521 - accuracy: 0.9570\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.3310 - accuracy: 0.9631\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.3000 - accuracy: 0.9590\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.2831 - accuracy: 0.9672\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.2595 - accuracy: 0.9693\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.2368 - accuracy: 0.9734\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.2264 - accuracy: 0.9734\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.2160 - accuracy: 0.9734\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.1982 - accuracy: 0.9734\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.1893 - accuracy: 0.9693\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.1787 - accuracy: 0.9672\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.1727 - accuracy: 0.9693\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.1619 - accuracy: 0.9754\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.1521 - accuracy: 0.9775\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.1470 - accuracy: 0.9734\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.1437 - accuracy: 0.9795\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.1369 - accuracy: 0.9795\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.1325 - accuracy: 0.9734\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.1281 - accuracy: 0.9734\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.1231 - accuracy: 0.9713\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.1180 - accuracy: 0.9754\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.1159 - accuracy: 0.9754\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.1105 - accuracy: 0.9754\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.1087 - accuracy: 0.9754\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.1046 - accuracy: 0.9754\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.1016 - accuracy: 0.9775\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0992 - accuracy: 0.9734\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0962 - accuracy: 0.9754\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0976 - accuracy: 0.9672\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0921 - accuracy: 0.9754\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0910 - accuracy: 0.9795\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0869 - accuracy: 0.9754\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0884 - accuracy: 0.9734\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.0841 - accuracy: 0.9795\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0867 - accuracy: 0.9734\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0835 - accuracy: 0.9775\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0807 - accuracy: 0.9795\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0821 - accuracy: 0.9775\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0801 - accuracy: 0.9754\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0821 - accuracy: 0.9754\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0764 - accuracy: 0.9795\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.0735 - accuracy: 0.9775\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0732 - accuracy: 0.9754\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0724 - accuracy: 0.9775\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0718 - accuracy: 0.9713\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0723 - accuracy: 0.9795\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0705 - accuracy: 0.9734\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0709 - accuracy: 0.9713\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0676 - accuracy: 0.9734\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0706 - accuracy: 0.9775\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0666 - accuracy: 0.9795\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.0661 - accuracy: 0.9775\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.0663 - accuracy: 0.9775\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0661 - accuracy: 0.9754\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0654 - accuracy: 0.9754\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.0632 - accuracy: 0.9754\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.0620 - accuracy: 0.9754\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0601 - accuracy: 0.9734\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0629 - accuracy: 0.9734\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0719 - accuracy: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x235a8092c40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61505a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 634ms/step\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "text = \"packages\"\n",
    "\n",
    "token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "# padding\n",
    "padded_token_text = pad_sequences([token_text], maxlen=X.shape[1], padding='pre')\n",
    "# predict\n",
    "pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da01e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "Lorem ipsum\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Lorem ipsum has\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Lorem ipsum has been\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Lorem ipsum has been the\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Lorem ipsum has been the industry's\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Lorem ipsum has been the industry's standard\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Lorem ipsum has been the industry's standard dummy\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Lorem ipsum has been the industry's standard dummy text\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Lorem ipsum has been the industry's standard dummy text ever\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Lorem ipsum has been the industry's standard dummy text ever since\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"Lorem\"\n",
    "\n",
    "for i in range(10):\n",
    "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "    # padding\n",
    "    padded_token_text = pad_sequences([token_text], maxlen=X.shape[1], padding='pre')\n",
    "    # predict\n",
    "    pos = np.argmax(model.predict(padded_token_text))\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "            text = text + \" \" + word\n",
    "            print(text)\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a7851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
